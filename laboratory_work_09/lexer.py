"""
–õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä - –¥–≤–µ –≤–µ—Ä—Å–∏–∏:
1. –î–ª—è —Ç–µ–∫—Å—Ç–∞ (—Å–ª–æ–≤)
2. –î–ª—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π (—Å–∏–º–≤–æ–ª–æ–≤)
"""

import re
from enum import Enum
from typing import List, Tuple

class TokenType(Enum):
    """–¢–∏–ø—ã —Ç–æ–∫–µ–Ω–æ–≤"""
    NUMBER = 'NUMBER'      # –ß–∏—Å–ª–∞
    PLUS = 'PLUS'          # +
    MINUS = 'MINUS'        # -
    MULTIPLY = 'MULTIPLY'  # *
    DIVIDE = 'DIVIDE'      # /
    POWER = 'POWER'        # ^
    SQRT = 'SQRT'          # sqrt
    LPAREN = 'LPAREN'      # (
    RPAREN = 'RPAREN'      # )
    WORD = 'WORD'          # –°–ª–æ–≤–∞ (—Ç–æ–ª—å–∫–æ –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ)
    EOF = 'EOF'            # –ö–æ–Ω–µ—Ü

class Token:
    """–¢–æ–∫–µ–Ω"""

    def __init__(self, type: TokenType, value: str = None, position: Tuple[int, int] = (0, 0)):
        self.type = type
        self.value = value
        self.start, self.end = position

    def __repr__(self):
        if self.value:
            return f"{self.type.name}('{self.value}')"
        return f"{self.type.name}"

# ============================================
# 1. –õ–ï–ö–°–ï–† –î–õ–Ø –¢–ï–ö–°–¢–ê (–°–õ–û–í–ê)
# ============================================

class TextLexer:
    """–õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Ç–µ–∫—Å—Ç–∞ (—Å–ª–æ–≤)"""

    def __init__(self, text: str):
        from dictionary import MathDictionary
        self.dict = MathDictionary
        self.text = self.dict.normalize_text(text)
        self.pos = 0
        self.current_char = self.text[0] if self.text else None

    def advance(self):
        """–ü–µ—Ä–µ—Ö–æ–¥–∏—Ç –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Å–∏–º–≤–æ–ª—É"""
        self.pos += 1
        if self.pos < len(self.text):
            self.current_char = self.text[self.pos]
        else:
            self.current_char = None

    def skip_whitespace(self):
        """–ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ–±–µ–ª—ã"""
        while self.current_char is not None and self.current_char.isspace():
            self.advance()

    def get_word(self) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ü–µ–ª–æ–µ —Å–ª–æ–≤–æ"""
        start_pos = self.pos
        result = ''

        while self.current_char is not None and not self.current_char.isspace():
            result += self.current_char
            self.advance()

        return result

    def get_next_token(self) -> Token:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω"""

        while self.current_char is not None:

            if self.current_char.isspace():
                self.skip_whitespace()
                continue

            # –ü–æ–ª—É—á–∞–µ–º —Å–ª–æ–≤–æ
            word = self.get_word()

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ª–æ–≤–æ –≤ —Å–∏–º–≤–æ–ª
            symbol = self.dict.word_to_symbol(word)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ç–æ–∫–µ–Ω–∞
            if symbol.isdigit() or (symbol[0] == '-' and symbol[1:].isdigit()):
                return Token(TokenType.NUMBER, float(symbol), (self.pos-len(word), self.pos))
            elif symbol == '+':
                return Token(TokenType.PLUS, '+', (self.pos-len(word), self.pos))
            elif symbol == '-':
                return Token(TokenType.MINUS, '-', (self.pos-len(word), self.pos))
            elif symbol == '*':
                return Token(TokenType.MULTIPLY, '*', (self.pos-len(word), self.pos))
            elif symbol == '/':
                return Token(TokenType.DIVIDE, '/', (self.pos-len(word), self.pos))
            elif symbol == '^   ':
                return Token(TokenType.POWER, '^', (self.pos-len(word), self.pos))
            elif symbol == 'sqrt':
                return Token(TokenType.SQRT, 'sqrt', (self.pos-len(word), self.pos))
            else:
                # –ï—Å–ª–∏ –Ω–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–ª–æ—Å—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ —Å–ª–æ–≤–æ
                return Token(TokenType.WORD, word, (self.pos-len(word), self.pos))

        return Token(TokenType.EOF)

    def tokenize(self) -> List[Token]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ç–æ–∫–µ–Ω—ã"""
        tokens = []

        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é
        self.pos = 0
        self.current_char = self.text[0] if self.text else None

        while True:
            token = self.get_next_token()
            tokens.append(token)
            if token.type == TokenType.EOF:
                break

        return tokens

    def pretty_print(self, tokens: List[Token]):
        """–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏—Ç —Ç–æ–∫–µ–Ω—ã"""
        print("\nüî§ –¢–û–ö–ï–ù–´ –ò–ó –¢–ï–ö–°–¢–ê:")
        print("-" * 40)
        for token in tokens[:-1]:  # –ù–µ –≤—ã–≤–æ–¥–∏–º EOF
            if token.type == TokenType.WORD:
                print(f"  {token.type.name:10} ‚Üí '{token.value}' (–Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ)")
            else:
                print(f"  {token.type.name:10} ‚Üí {token.value}")
        print("-" * 40)

# ============================================
# 2. –õ–ï–ö–°–ï–† –î–õ–Ø –ú–ê–¢–ï–ú–ê–¢–ò–ö–ò (–°–ò–ú–í–û–õ–´)
# ============================================

class MathLexer:
    """–õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""

    def __init__(self, text: str):
        self.text = text
        self.pos = 0
        self.current_char = self.text[0] if text else None

    def error(self, message: str):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—à–∏–±–∫—É"""
        raise Exception(f'–û—à–∏–±–∫–∞ –ª–µ–∫—Å–µ—Ä–∞: {message} –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ {self.pos}')

    def advance(self):
        """–ü–µ—Ä–µ—Ö–æ–¥–∏—Ç –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Å–∏–º–≤–æ–ª—É"""
        self.pos += 1
        if self.pos < len(self.text):
            self.current_char = self.text[self.pos]
        else:
            self.current_char = None

    def skip_whitespace(self):
        """–ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ–±–µ–ª—ã"""
        while self.current_char is not None and self.current_char.isspace():
            self.advance()

    def number(self) -> Token:
        """–°—á–∏—Ç—ã–≤–∞–µ—Ç —á–∏—Å–ª–æ"""
        start_pos = self.pos
        result = ''

        # –°—á–∏—Ç—ã–≤–∞–µ–º —Ü–µ–ª—É—é —á–∞—Å—Ç—å
        while self.current_char is not None and self.current_char.isdigit():
            result += self.current_char
            self.advance()

        # –î—Ä–æ–±–Ω–∞—è —á–∞—Å—Ç—å
        if self.current_char == '.':
            result += '.'
            self.advance()
            while self.current_char is not None and self.current_char.isdigit():
                result += self.current_char
                self.advance()

        try:
            value = float(result)
            return Token(TokenType.NUMBER, value, (start_pos, self.pos))
        except:
            self.error(f"–ù–µ–≤–µ—Ä–Ω–æ–µ —á–∏—Å–ª–æ: {result}")

    def get_next_token(self) -> Token:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω"""

        while self.current_char is not None:

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
            if self.current_char.isspace():
                self.skip_whitespace()
                continue

            # –ß–∏—Å–ª–∞
            if self.current_char.isdigit():
                return self.number()

            # –û–ø–µ—Ä–∞—Ç–æ—Ä—ã
            if self.current_char == '+':
                self.advance()
                return Token(TokenType.PLUS, '+', (self.pos - 1, self.pos))

            if self.current_char == '-':
                self.advance()
                return Token(TokenType.MINUS, '-', (self.pos - 1, self.pos))

            if self.current_char == '*':
                self.advance()
                return Token(TokenType.MULTIPLY, '*', (self.pos - 1, self.pos))

            if self.current_char == '/':
                self.advance()
                return Token(TokenType.DIVIDE, '/', (self.pos - 1, self.pos))

            if self.current_char == '^':
                self.advance()
                return Token(TokenType.POWER, '^', (self.pos - 1, self.pos))

            # –°–∫–æ–±–∫–∏
            if self.current_char == '(':
                self.advance()
                return Token(TokenType.LPAREN, '(', (self.pos - 1, self.pos))

            if self.current_char == ')':
                self.advance()
                return Token(TokenType.RPAREN, ')', (self.pos - 1, self.pos))

            # –¢–æ—á–∫–∞ –≤ –Ω–∞—á–∞–ª–µ —á–∏—Å–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, .5)
            if self.current_char == '.':
                # –≠—Ç–æ –Ω–∞—á–∞–ª–æ –¥—Ä–æ–±–Ω–æ–≥–æ —á–∏—Å–ª–∞ –±–µ–∑ —Ü–µ–ª–æ–π —á–∞—Å—Ç–∏
                return self.number()

            # –§—É–Ω–∫—Ü–∏—è sqrt
            if self.current_char == 's':
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ "sqrt" –ª–∏ —ç—Ç–æ
                if self.pos + 4 <= len(self.text) and self.text[self.pos:self.pos + 4] == 'sqrt':
                    start_pos = self.pos
                    for _ in range(4):
                        self.advance()
                    return Token(TokenType.SQRT, 'sqrt', (start_pos, self.pos))
                else:
                    self.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–∏–º–≤–æ–ª: {self.current_char}")

            self.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–∏–º–≤–æ–ª: '{self.current_char}'")

        return Token(TokenType.EOF)

    def tokenize(self) -> List[Token]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ç–æ–∫–µ–Ω—ã"""
        tokens = []

        self.pos = 0
        self.current_char = self.text[0] if self.text else None

        while True:
            token = self.get_next_token()
            tokens.append(token)
            if token.type == TokenType.EOF:
                break

        return tokens

    def pretty_print(self, tokens: List[Token]):
        """–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏—Ç —Ç–æ–∫–µ–Ω—ã"""
        print("\nüî£ –¢–û–ö–ï–ù–´ –ò–ó –ú–ê–¢–ï–ú–ê–¢–ò–ö–ò:")
        print("-" * 40)
        for token in tokens[:-1]:  # –ù–µ –≤—ã–≤–æ–¥–∏–º EOF
            print(f"  {token.type.name:10} ‚Üí {token.value}")
        print("-" * 40)